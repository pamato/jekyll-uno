---
title: "Introduction to Social Network Analysis - Lab 2"
author: "Paulo Serôdio"
output:
  html_document:
    theme: readable
    highlight: zenburn
    code_folding: show
    df_print: kable
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: no
---


Start from clean slate and free up memory

```{r tidy=TRUE, results=FALSE}
rm(list = ls())
gc()
```

Load R packages

```{r, message=FALSE, warning=FALSE}
library(statnet)
library(sna)
library(network)
library(tidyverse)
```



```{r}
## Load data

load("./data/ac-net-env-case.RData")
```


- Novel network dataset on all 275 interest groups that coauthored amicus curiae briefs for 2000–2009 Supreme Court cases on natural resources and environmental protection.
- Ties are determined by whether two groups have cosigned a brief on the same case at least once;
- A reviewer noted that this is naturally a value-edged network as groups can coauthor on multiple briefs during the 2000–2009 period. We make the decision to binarize this network;
- Amicus curiae briefs, or ``friend of the court briefs'', reflect the public position of a particular entity not involved in a court case with respect to the issues being heard.
- Their purpose is to provide evidence, opinion, and testimony that the parties directly involved in the case may not provide. Amicus curiae partic- ipation requires a statement on the position of a group, and cosign- ing the same brief indicates coordinated efforts with a shared purpose.
- This novel dataset where interest groups are tied to one another through coauthoring the same brief captures a purposive and coordinated network of interest groups lobbying collectively on environmental policy issues. Once the network is assembled, our first step is to focus on the roles of actors within a network. 



```{r}

# Number edges:
network.edgecount(net)

# Number of nodes:
network.size(net)

# Node IDs
network.vertex.names(net)[1:10]

```

Convert `network` object into edgelist

```{r}
mat <- as.matrix(net, matrix.type="edgelist")
```

Check for attributes

```{r}
# network attr
list.network.attributes(net)
get.network.attribute(net, "mnext") # Number of nodes

# node attr
list.vertex.attributes(net)

# edge
list.edge.attributes(net)
get.edge.attribute(net, "case1")
```

Retrieve all node attributes and store in data.frame

```{r}
attributes.list <-list.vertex.attributes(net)
attributes <- data.frame(sapply(attributes.list, function(x) get.vertex.attribute(net, x)))
attributes$node_id <- network.vertex.names(net)

```

Retrieve all edge attributes and store in data.frame (these are essentially multiple edgelists)
```{r}
# Get edge attributes (list of amicus briefs SIGs signed together)
edgeatttr.list <- list.edge.attributes(net)
edge.attributes <- as.matrix(sapply(edgeatttr.list, function(x) get.edge.attribute(net,x)))
# Add edge attributes to edge.list
complete.matrix <- data.frame(cbind(mat, edge.attributes))
colnames(complete.matrix)[1:2] <- c("source", "target")
# Create edge weight = count of number of amicus briefs co-signed for edge dyad
complete.matrix$edge_value <- rowSums(sapply(colnames(complete.matrix[grep("(case)[[:digit:]]", names(complete.matrix))]), function(x) ifelse(is.na(complete.matrix[[x]]), 0, 1)))
valued.mat <- complete.matrix[, c(1,2,ncol(complete.matrix))]
valued.mat[1:10,]
```



```{r, echo=FALSE}
kableExtra::kable(head(attributes)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = FALSE))

```



# Embeddedness and bridging


Breiger & Pattison (1986), in their discussion of local role analysis, use a subset of data on the social relations among Renaissance Florentine families (person aggregates) collected by John Padgett in 1994 from historical documents. The two relations are business ties (flobusiness - specifically, recorded financial ties such as loans, credits and joint partnerships) and marriage alliances (flomarriage).

As Breiger & Pattison point out, the original data are symmetrically coded. This is acceptable perhaps for marital ties, but is unfortunate for the financial ties (which are almost certainly directed). To remedy this, the financial ties can be recoded as directed relations using some external measure of power - for instance, a measure of wealth. Both networks provide vertex information on (1) wealth each family's net wealth in 1427 (in thousands of lira); (2) priorates the number of priorates (seats on the civic council) held between 1282- 1344; and (3) totalties the total number of business or marriage ties in the total dataset of 116 families (see Breiger & Pattison (1986), p 239).

Substantively, the data include families who were locked in a struggle for political control of the city of Florence in around 1430. Two factions were dominant in this struggle: one revolved around the infamous Medicis (9), the other around the powerful Strozzis (15).

```{r}
library(tidyverse)
# if you're interested in exploring the complete dataset, check it here
florentine.families <- rio::import("./data/florentine_families_relations_full.xlsx")
# Group by family surname and sum over ties
flo.marriage.fam <- florentine.families %>% filter(Relationship_type=="Marriage") %>% group_by(sender=tolower(Actor1surname), receiver=tolower(Actor2surname)) %>% summarise(Tie_coding= n())
flo.g <- igraph::graph_from_data_frame(flo.marriage.fam)
igraph::V(flo.g)$color <- as.factor(igraph::V(flo.g)$name)
# Plot
igraph::plot.igraph(flo.g, vertex.label=NA, vertex.size = 5, layout=igraph::layout.fruchterman.reingold,
                    edge.arrow.size=0.2)
```

```{r}
# We'll analyze a subset of this data
data(florentine)
# Bring attribute data for subset of the network
flo.attr <- rio::import("./data/florentine_attributes_subset.xlsx")
g <- snatools::as_igraph(flomarriage)
igraph::V(g)$faction <- as.character(flo.attr$faction[order(flo.attr$family)])
# Color the party factions
igraph::V(g)$color <- igraph::V(g)$faction
igraph::V(g)$color <- gsub("medici","gold",igraph::V(g)$color) # Medici are gold
igraph::V(g)$color <- gsub("oligarchs","blue",igraph::V(g)$color) # Oligarchs are blue
igraph::V(g)$color <- gsub("split","gray70",igraph::V(g)$color) # Split affiliat ion is gray
igraph::V(g)$color
igraph::plot.igraph(g, layout=igraph::layout.fruchterman.reingold, vertex.label.cex=0.75)
```

## Cutpoints

```{r}
g %>%
  igraph::articulation_points() %>%
  as.list() %>%
  names() %>%
  as.data.frame() %>%
  `colnames<-`("Cut Points")

igraph::V(g)$color = ifelse(igraph::V(g) %in% igraph::articulation_points(g), "salmon", "lightblue")
plot(g, vertex.label.cex=.75, edge.width = 5)


```

## Weak ties & Reachability

We will look at the neighbourhood of a node, two or three steps out. Below, we generate a function to count the number of neighbours at two and three steps out:

```{r}

# Function for 2-step reach
reach2<-function(x){ 
          r=vector(length=igraph::vcount(x)) 
          for (i in 1:igraph::vcount(x)){ 
            n=igraph::neighborhood(x,2,nodes=i) 
            ni=unlist(n)
            l=length(ni)
            r[i]=(l)}
          r}

# Function for 3-step reach 
reach3<-function(x){
          r=vector(length=igraph::vcount(x)) 
          for (i in 1:igraph::vcount(x)){ 
            n=igraph::neighborhood(x,3,nodes=i) 
            ni=unlist(n)
            l=length(ni)
            r[i]=(l)}
          r}

Reach_2 <- reach2(g) 
Reach_3 <- reach3(g) 
```

To see how many **weak ties** each node has, we first need to calculate how many nodes are in each node’s neighborhood at two steps out (`reach2`). Then, we need only subtract the number of nodes that are ajacent to the node (`degree).

```{r}
Reach_2 - igraph::degree(g)
```


# Roles & Positions

- Examining roles through the a networks-based lens can explain why actors select into a network, how certain organizations benefit the larger collective, and the dynamics that influence successful lobbying. 
- Roles emerge from structural features of a community and reflect commonalities in behavior. 
- detecting the structural position of nodes within a network allows for statements about the roles that actors adopt.
- Take for example, the roles that states may adopt in international politics. Many theories of interna- tional politics are intrinsically about the roles that states may adopt when interacting with one another. Consider balance of power the- ory, a hallmark of international relations describing how states at- tempt to preserve their security by balancing stronger states. This the- ory is intrinsically about the roles that states may adopt as aggres- sors, defenders, or balancers
- these roles greatly influence their behavior and broader sys- tem-level dynamics, making them more prone to war or peace, or more influential in the development of international norms.


## Burt's **Structural Holes** (Topological)

Burt's (1992) measures of **structural holes** are supported by iGraph and ego network variants of these measures are supported by `egonet`; this package is compatable with the `sna` package.

However, `egonet` has been removed from CRAN. So, we install it locally from an older version.

```{r}
install.packages("./packages/egonet", repos = NULL, type = "source")
?egonet::`egonet-package`
```
A small tool for Social Network Analysis, dealing with ego-centric network measures, including Burt's effective size and aggregate constraint and an import code suitable for a large number of adjacency matrices.

The Egonet package is also available as free web application on http://www.egonet.associazionerospo.org (and an example of output can be seen here: http://www.egonet.associazionerospo.org/egonetdata/EgonetOutput.htm)



+ Using **data from grant applications** made between 2012 and 2013 by faculty in a a major US university

```{r}
year <- seq(2012, 2013, by=1)
for (y in year){
  edgelist.name <- paste("matrix", y, sep=".")
  attr.name <- paste("attr", y, sep=".")
  net.name <- paste("net", y, sep=".")
  edgelist.data <- as.matrix(table(rio::import(paste("./data/edgelist", y, ".dta", sep=""))))
  edgelist.data <- edgelist.data %*% t(edgelist.data)
  diag(edgelist.data) <- 0
  edgelist.data[edgelist.data > 1] <- 1
  attr.data <- rio::import(paste("./data/attr", y, ".dta", sep=""), convert.factors=F)
  network <- network::network(edgelist.data, directed=FALSE,ignore.eval=FALSE,names.eval='grants')
  #edgelist.data <- edgelist.data[-isolates(network), -isolates(network)] # remove isolates
  #attr.data <- attr.data[-]
  assign(edgelist.name, value = edgelist.data)
  assign(attr.name, value=attr.data)
  assign(net.name, value=network)
  rm(edgelist.data, attr.data, attr.name, edgelist.name, network, net.name)
}
```

```{r }

# Remove isolates
mat12 <- matrix.2012[-sna::isolates(net.2012), -sna::isolates(net.2012)]
attributes.12 <- attr.2012[-c(sna::isolates(net.2012)),]
mat13 <- matrix.2013[-sna::isolates(net.2013), -sna::isolates(net.2013)]
attributes.13 <- attr.2013[-c(sna::isolates(net.2013)),]
```


```{r }
# Extract ego-networks and calculate measures
ego.nets.12 <- sna::ego.extract(mat12, neighborhood="combined")
results.12 <- data.frame(piid = attributes.12$piid, gender = attributes.12$gender, ego=NA,
                      effsize = NA, constraint = NA, efficiency = NA, hierarchy = NA, size = NA)
for (i in 1:length(ego.nets.12)){
  ego <- names(ego.nets.12[i])
  ego.net <- ego.nets.12[i][[1]]
  dimnames(ego.net) <- NULL
  colnames(ego.net) <- rownames(ego.net) <- c("EGO", 2:ncol(ego.net))
  # Get structural holes measures from egonet package
  sh <- egonet::index.egonet(ego.net)
  results.12$size[i] <- nrow(ego.net)-1
  results.12$ego[i] <- ego
  results.12$effsize[i] <- sh[1]
  results.12$constraint[i] <- sh[2]
  results.12$efficiency[i] <- sh[5]
  results.12$hierarchy[i] <- sh[6]
}

# Store average SH mesaures by some attribute

effsize.g <- results.12 %>% group_by(gender) %>% summarise(mean = mean(effsize))
constraint.g <- results.12 %>% group_by(gender) %>% summarise(mean = mean(constraint))
efficiency.g <- results.12 %>% group_by(gender) %>% summarise(mean = mean(efficiency))
hierarchy.g <- results.12 %>% group_by(gender) %>% summarise(mean = mean(hierarchy))
size.g <- results.12 %>% group_by(gender) %>% summarise(mean = mean(size))

# Push the results
table(results.12$size[results.12$gender == "Female"])
table(results.12$size[results.12$gender == "Male"])
plot(density(results.12$size[results.12$gender == "Male"]))
plot(density(results.12$size[results.12$gender == "Female"]))

```



## Brokerage (Gould & Fernandez topology+attributes)

The brokerage measure included in the `sna` package (hint: it needs a `network` object) builds on past work on borkerage (Marsden 1982), but is a more explicitly group oriented measure. Unlike Burt's (1992) measure, the Gould-Fernandez measure requires specifying a group variable based on an attribute. We will use race in the example below.
  
**Brokerage Roles*: a group-based concept

  - `w_I`: **Coordinator**, mediates Within Group Contact ($A \rightarrow A \rightarrow A$)
  - `w_O`: **Itinerant Broker**/**Consultant**, mediates contact between individuals in a group to which the actor does not belong ($A \rightarrow B \rightarrow A$) 
  - `b_{IO}`: **Representative**, mediates incoming contact from out-group members ($A \rightarrow B \rightarrow B$)
  - `b_{OI}`: **Gatekeeper**, mediates outgoing contact from in-group members, ($A \rightarrow A \rightarrow B$)
  - `b_O`: **Liason Role**, mediates contact between individuals of two differnt groups, neither of which the actor belongs, ($A \rightarrow B \rightarrow C$)
  - `t`: Total or Cumulative Brokerage (total number of time a node fills any of the above roles)

If you run the function without `$raw.nli` appended to the end, you will see that it produces fourteen different forms of output. It is worth mentioning that you can also produce a normalized score that will give the magnitude of the differences between nodes, rather than the raw number of times. Use this approach if you prefer to simplify the table by displaying how the nodes differ by order of magnitude.

The brokerage function does this by providing normalized output that is scaled on the z distribution, referred to "z scores". Z scores are calculated by comparing each number to the average for the distribution and dividing by the standard deviation.

$$z = \frac{x - \bar{x}}{s}$$
In the results you'll encounter both positive and negative valyes (the scale is cetered at 0). Consider that anything grater than 1.96 or less than -1.96 (2 sd away from the mean) is significantly different from the "typical" at p=0.05 level of significance. This is helpful to identify the nodes that stand out by being statistically significantly greater/less than the average for the network.

To produce normalized scores add `z.nli` to the function. Use `round()` to reduce number of digits.


Type `?brokerage` for more information
  

+ **Using faculty grant application data**

```{r, eval=FALSE, include=FALSE}
### Brokerage Roles ###
mat12 <- matrix.2012[-isolates(net.2012), -isolates(net.2012)]
attributes.12 <- attr.2012[-c(isolates(net.2012)),]


# Gender Brokerage; observed scores
brokerage.12 <- brokerage(mat12, attributes.12$gender)
summary(brokerage.12)
positions <- data.frame(brokerage.12$z.nli) # Raw Observed Brokerage Scores by vertex
colnames(positions) <- c("piid", "coordinator", "consultant", "representative",
                         "gatekeeper", "liaison")
positions$gender <- attributes.12$gender

coord <- ddply(positions, .(gender), summarize, sum=mean(coordinator))
consul <- ddply(positions, .(gender), summarize, sum=mean(consultant))
rep <- ddply(positions, .(gender), summarize, sum=mean(representative))
gate <- ddply(positions, .(gender), summarize, sum=mean(gatekeeper))
liaison <- ddply(positions, .(gender), summarize, sum=mean(liaison))
```


+ ** Using Add Health data **

```{r}
# Import data, create network object
AHS.Nodes <- load("./data/AHS_nodes.Rda")
AHS.Edges <- load("./data/AHS_edges.Rda")
ahs.net <- network::network(AHS_Edges, matrix.type = "edgelist")
network::set.vertex.attribute(ahs.net, "Race", AHS_Nodes$race5)

# Calculate roles & position counts
AHS_Brokerage <- sna::brokerage(ahs.net, "Race")
# Raw scores
head(AHS_Brokerage$raw.nli)
# Raw and Normalized scores rounded to 2 digits
head(round(AHS_Brokerage$z.nli, 2))
```


# Homophily & Heterogeneity

## E-I index

$$ \textbf{E-I Index} = \frac{E - I}{E + I} $$
*E-I Index* was proposed by Krackhard and Stern (1988) to capture relative prevalence of between- and within-group ties. From that perspective it can be interpreted as a measure of network segregation.

The E-I Index is not common to many R packages, and it is not as simple as it seems to program. To make your life simpler, it is necessary to first install a package called `isnar`, written and maintained by Michal Bojanowski as a supplement to `igraph`. It is only available through Git Hub, as it's an R package in development.

```{r, eval=FALSE, message=FALSE, warning=FALSE}
devtools::install_github("mbojan/isnar")

```


The generic method for using the E-I Index in isnar is `ei(g, "attribute")` , where `g` is an igraph object, with a qualitative attribute (`attribute`) assigned to each of the vertices.

```{r}
# Convert our Add Health network object to igraph
ahs.g <- snatools::as_igraph(ahs.net)
# Run E-I Index
isnar::ei(ahs.g, "Race")
plot(g, layout=igraph::layout.fruchterman.reingold, vertex.label=NA)
```



## Index of Qualitative Variation

The index of qualitative variation (IQV) is a measure of variation among the categories of a qualitative variable. It is calculated as

$$ 1 - \sum p_2 * (\frac{k}{k-1})$$ ,

where $p$ is the proportion in each category, and K is the number of categories. The variable ranges from 0 to 1, where 0 represents a completely homogeneous group, and 1 represents a group with equal parts in each category.

The function below also returns Blau's index. It takes as input a matrix and an attribute vector.

```{r}
get_iqvs <- function(matrix, attribute) {
 
    mat <- matrix
    attr_levels = attribute
    num_levels = length(unique(attr_levels))
    iqvs = rep(0, nrow(mat))
    blau_index = rep(0, nrow(mat))
 
    for (ego in 1:nrow(mat)) {
         
        # initialize actor-specific variables
        alter_attr_counts = rep(0, num_levels)
        num_alters_this_ego = 0
        sq_fraction_sum = 0
     
        for (alter in 1:ncol(mat)) {
             
            # only examine alters that are actually tied to ego
            if (mat[ego, alter] == 1) {
                 
                num_alters_this_ego = num_alters_this_ego + 1
 
                # get the alter's level on the attribute 
                alter_attr = attribute[alter]
 
                # increment the count of alters with this level
                # of the attribute by 1
                alter_attr_counts[alter_attr] <- alter_attr_counts[alter_attr] + 1
            }
        }
 
         for (i in 1:num_levels) {
            attr_fraction = alter_attr_counts[i] /
                num_alters_this_ego
            sq_fraction_sum = sq_fraction_sum + attr_fraction ^ 2
        }
         
        # now we can compute the ego's blau index...
        blau_index[ego] = 1 - sq_fraction_sum
        # and the ego's IQV, which is just a normalized blau index
        iqvs[ego] = blau_index[ego] / (1 - (1 / num_levels))
    }
 
    return(list(iqvs, blau_index))
}
```

```{r}
ahs.mat <- igraph::as_adjacency_matrix(ahs.g)
ahs.attr <- igraph::get.vertex.attribute(ahs.g)$Race

ahs_iqv <- get_iqvs(ahs.mat, ahs.attr)[[1]]
ahs_blau <- get_iqvs(ahs.mat, ahs.attr)[[2]]
```

If you prefer to use an `igraph` object, use the following function.
**Warning**: it will deploy `igraph` into the environment. Prepare for conflicts.
TAKE SHELTER!

```{r}
iqv <- function(graph, attribute) {
    require(igraph) 
    N <- length(igraph::V(graph))
    cats <- unique(igraph::get.vertex.attribute(graph,attribute,igraph::V(graph)))
    nlev <- length(cats)
    cat_list <- rep(0,N)
    p <- rep(0, N) 
    p2_list <- as.list(0)
    for (j in 1:nlev) {
      for(i in 1:length(igraph::V(graph))){
        i_att <- igraph::get.vertex.attribute(graph, attribute, igraph::V(graph)[igraph::neighborhood(graph,1)[[i]]]) 
        att <- length(which(i_att==cats[j]))
        num <- length(igraph::V(graph)[igraph::neighborhood(graph, 1)[[i]]])
        p[i]<-att/num
        p2<-p*p
      }
      p2_list[[j]] <- p2
      cat_list <- cat_list + p2
    }
    IQV <- (nlev/(nlev-1))*(1-cat_list)
    IQV1 <- as.list(0)
    IQV1[[2]] <- IQV
    IQV1[[1]] <- mean(IQV)
    names(IQV1) <- c("full_graph", "egonet")
    return (IQV1)
    detach("package:igraph", unload=TRUE)
  } 
```

```{r, eval=FALSE}
V(ahs.g)$iqv <- iqv(ahs.g, "Race")
```


- IQV using grant activity data

```{r}
# Prepare data with two attributes: gender and department
### Data
mat12 <- matrix.2012[-isolates(net.2012), -isolates(net.2012)]
mat13 <- matrix.2013[-isolates(net.2013), -isolates(net.2013)]
attributes.12 <- attr.2012[-c(isolates(net.2012)),]
attributes.13 <- attr.2013[-c(isolates(net.2013)),]
## Attributes
dep.12 <- as.numeric(as.factor(attributes.12$department))
gender.12 <- as.numeric(as.factor(attributes.12$gender))
```

```{r}
# Run IQV and plot
## Inter-disciplinary heterogeneity by gender

iqv.dep <- get_iqvs(mat12, dep.12)[[1]] ## Heterogeneity by discipline
iqv.male <- iqv.dep[gender.12 == 2]
iqv.female <- iqv.dep[gender.12 == 1]
iqv.male.mean <- mean(iqv.dep[gender.12 == 2]) # 0.395
iqv.female.mean <- mean(iqv.dep[gender.12 == 1]) # 0.397
iqv.male.sd <- sd(iqv.dep[gender.12 == 2]) # 0.344
iqv.female.sd <- sd(iqv.dep[gender.12 == 1]) # 0.353
heterogeneity <- data.frame(gender = attributes.12$gender,iqv = 0)
heterogeneity$iqv[which(attributes.12$gender == "Male")] <- iqv.male
heterogeneity$iqv[which(attributes.12$gender == "Female")] <- iqv.female
means <- data.frame(measure = heterogeneity$iqv, cond = heterogeneity$gender)
means <- means %>% group_by(cond) %>% summarise(cent.mean=mean(measure))


# Plot
ggplot(data = heterogeneity, aes(x = iqv, fill=gender)) +
            #geom_histogram(alpha=.5, position="identity") +
            geom_density(alpha=.7) + 
            geom_vline(data=means, aes(xintercept=means$cent.mean),  colour=c("#FF8585", "#19A3FF"),
            linetype="dashed", size=1, alpha=.7) + ylim(0,3.2) + xlim(0,1) + 
            theme(axis.text.x = element_text(angle = 45, hjust = 1),
            axis.title.y = element_text(size=14), axis.title.x  = element_text(size=12)) +
            xlab("Heterogeneity Index") + ylab("") + ggtitle("2012") + ylab("Density") +
            scale_fill_manual(name = "Gender", values = c("#FF8585", "#19A3FF"))
```


# Equivalences


## Structural Equivalence with CONCOR

The original **CONCOR** algorithm was developed by Ron Breiger, Scott Boorman, and Phipps Arabie. If you are interested, you can check out their original (1975) paper: [“An Algorithm for Clustering Relational Data with Applications to Social Network Analysis and Comparison with Multidimensional Scaling. Journal of Mathematical Psychology, 12: 328– 383.](http://sci-hub.tw/https://doi.org/10.1016/0022-2496(75)90028-0). The original version was written in Fortran. Since then, Adam Slez has rewritten the program in R.

Although it was developed with structural equivalence in mind, CONCOR is used for equivalence in general, since we rarely expect to see true structrual equivalence in a network.
Because Adam Slez has not committed his `concoR` package to CRAN, we will have to install it from his github site. You will only have to do this once.

CONCOR requires a matrix, or stack of matrices to make its calculations. So, start by loading concoR and extracting a matrix from
an igraph network.


```{r eval=F, echo=F}
#library(concoR)
# Florentine families in igraph
g <- snatools::as_igraph(flomarriage)
# Florentine families in network
net <- flomarriage
# Convert the network to a matrix
mat <- as.matrix(igraph::get.adjacency(g))
```

* Using **Roethlisberger & Dickson Bank Wiring Room** 

- These are the observational data on 14 Western Electric (Hawthorne Plant) employees from the bank wiring room first presented in Roethlisberger & Dickson (1939). The data are better known through a scrutiny made of the interactions in Homans (1950), and the CONCOR analysis presented in Breiger et al (1975).

- The employees worked in a single room and include two inspectors (I1 and I3), three solderers (S1, S2 and S3), and nine wiremen or assemblers (W1 to W9). The interaction categories include: RDGAM, participation in horseplay;  RDCON, participation in arguments about open windows;  RDPOS, friendship;  RDNEG, antagonistic (negative) behavior; RDHLP, helping others with work; and RDJOB, the number of times workers traded job assignments.

```{r}
# load Bank Wiring dataset: 

net <- flomarriage
data(bank_wiring)
bank.wiring.net <- sna::as.sociomatrix.sna(net)
gplot(bank.wiring.net)

```

Next, run the concoR algorithm to identify the various structrual equivalence "blocks".

Functional note: The `list()` function in `concor_hca` is necessary if you are using only one matrix. The program was developed to work with `arrays` (lists of matrices), so it doesn’t play well with single matrices without this command.

```{r}
blks <- concoR::concor_hca(bank_wiring, p=2)
blks
```

The output gives the vertex names, as well as the "blocks" or classes that each vertex was classified into. We can visualize this information in one of two ways: as a block matrix, or as a network visualization. We’ll do each below.

First, we can plot the network in `statnet`, using the `blockmodel` function. Note: we input the `network` object for the Florentine network along with the output of the `concor_hca` function.

 
 
```{r}
blk_mod <- sna::blockmodel(net, blks$block)
blk_mod
```

* Plot as a blockmodel matrix

```{r}
plot(blk_mod)
```

* Plot as a network

```{r}
# Add the block designations to igraph data
igraph::V(g)$blocks <- blks$block
igraph::plot.igraph(g, vertex.color=igraph::V(g)$blocks) 
```

### Optimization


Aleš Žiberna has written the `blockmodeling` package on `R`.

```{r, eval=FALSE}
install.packages("blockmodeling")
install.packages("./packages/rngtools", repos = NULL, type = "source")
```

```{r, eval=FALSE, message=FALSE, warning=FALSE}
library(blockmodeling)
```

The "optimization"" approach is where you assign some number of random partitions and require the algorithm to re-sort the network to a point where the various blocks contain a best fit to the network. There are a number of possible options for soting the network under the command. Here, we use the sum of squares methods. Also, the command asks the algorithm to find “complete” blocks (all 1s, and no 0s) if possible. Try it with and without this.

For more information see [ŽIBERNA, Aleš (2007): Generalized Blockmodeling of Valued Networks. Social Networks, Jan. 2007, vol. 29, no. 1, 105-126](https://sci-hub.se/http://dx.doi.org/10.1016/j.socnet.2006.04.002).

```{r, eval=FALSE}
# Extract the matrix in igraph
mat <- as.matrix(get.adjacency(g)) 
# Try a two block partition.
class2 <- blockmodeling::opt.random.par(M=mat, k=2, rep=10, approach="ss", blocks="com")
# Tru a four block partition
class4 <- opt.random.par(M=mat, k=4, rep=10, approach="ss", blocks="com")
```

```{r, eval=F}
par(mfrow=c(1,2)) # set the plot window for one row and
 two columns
plot(class2, main="")
  title("Two Block Partition")
plot(class4, main="")
  title("Four Block Partition")
par(mfrow=c(1,1)) # reset the plot window back to one ro
w and one column
```

```{r, eval=F}
# See what is packed into the outpute object
ls(class4)
class4$best  #  Look inside "best"
# The best partition can therefore be found in:
class4$best$best1$clu
```

We can use the partition the same way we did in `concoR` . Add the partition to the network and plot it in `igraph`.

```{r, eval=F}
# Add the block designations to igraph data
V(g)$opt.blocks <- class4$best$best1$clu
plot.igraph(g, vertex.color=V(g)$opt.blocks) # plot in i
graph
```


### Euclidean Distances

Euclidean distance is a method of calculating similarities by comparing common distances from some nodes to other nodes. It may be used for either structural equivalence or automorphic equivalence.
Below is a modification of what Carter Butts wrote into `sna`.

```{r}
#Cluster based on structural equivalence
# BEWARE: The blockmodeling package interferes with this function.
# Detach blockmodeling before you begin. detach("package:blockmodeling", unload=TRUE)
eq<-sna::equiv.clust(net,method="euclidean",mode="graph")
# Form a blockmodel
b<-sna::blockmodel(net, eq, h=4, mode = "graph") # h = 4 is the highest you can go for Medici
plot(b)      # Plot it
```


## Regular Equivalence

### REGE

REGE is actually a set of algorithms that compute similarities - or dissimilarities - between vertices that equate to regular equivalence.

`REGE`, `REGE.for` - Classical REGE or REGGE, as also implemented in Ucinet. Similarities in terms of regular equivalence are computed. The REGE.for is a wrapper for calling the FORTRAN subrutine written by White (1985a), modified to be called by R. The REGE does the same, however it is written in R. The functions with and without ".for" differ only in whether they are implemented in R of FORTRAN. Needless to say, the functions implemented in FORTRAN are much faster.

REGE.ow, REGE.ow.for - The above function, modified so that a best match is searched for each arc separately (and not for both arcs, if they exist, together).

REGE.ownm.for - The above function, modified so that a best match for an outgoing ties is searched on row-normalized network and for incoming ties on column-normalized network.

```{r}
mat <- as.matrix(igraph::get.adjacency(g)) # Extract the matrix in igraph (if you haven't already)
D<-blockmodeling::REGE(M=mat)$E
blockmodeling::plot.mat(mat, clu=cutree(hclust(d=as.dist(1-D),method="ward.D"),k=4))  #REGE returns similarities, which have to be converted to disimilarities
```

```{r}
# Try another variation of REGE
D2<-blockmodeling::REGE.ownm.for(M=mat)$E
blockmodeling::plot.mat(mat, clu=cutree(hclust(d=as.dist(1-D2),method="ward.D"),k=4))
```


# Practicum: application to militarized interstate disputes

Militarized interstate disputes are widely thought to be less likely among democratic countries that have high levels of trade and extensive participation in international organizations. 

Much of the statistical association typically reported in this literature apparently stems from three components: a) geographical proximity, b) dependence among militarized interstate disputes with the same initiator or target, and c) the higher-order dependencies in these dyadic data.

Once these are incorporated, covariates associated with the Kantian peace tripod (democracy, trade, and international governmental organizations) tend to lose most of their statistical power.

Despite high statistical significance and putative substantive importance, none of the variables representing the Kantian tripod is associated with any substantial degree of predictive power.

Using data from Peterson's 2014 JCR ["Dyadic Trade, Exist costs and conflict"](http://sci-hub.se/10.1177/0022002713478794)

**Abstract:**

"Most studies of the link between dyadic trade and militarized conflict examine the extent of trade interaction. However, interaction measures do not account for the impact of cutting off trade (i.e., exit costs). In this article, I highlight the link between exit costs, the cost of conflict, and “the spoils of conquest,” arguing that one state’s exit costs are associated with higher incidence of dyadic conflict when its trade partner’s exit costs are low. However, its exit costs become less aggravating—and eventually pacifying—as its trade partner’s exit costs increase. I test this argument by estimating import demand and export supply elasticities, developing yearly exit cost measures for directed dyads, 1984–2000. Statistical tests confirm that unilaterally high exit costs are aggravating, but that jointly high exit costs are pacifying, a pattern most prominent for trade in strategic commodities."


```{r}
peterson <- rio::import("./data/JCR_rep_data.dta")
#install.packages("countrycode")
library(countrycode)
peterson$cname1 <- countrycode(peterson$ccode1, "cown", "cowc")
peterson$cname2 <- countrycode(peterson$ccode2, "cown", "cowc")
peterson <- peterson %>% select(ccode1, ccode2, cname1, cname2, year, fcwinit, fcwongo, lndist, fincthc, finctlc, polity1_adj, polity2_adj, polity_int, s_wt_glo)
```

Description of variables

- `ccode1`, Correlates of War code number for state 1
- `ccode2`, Correlates of War code number for state 2
- `cname1`, Name State 1
- `cname2`, Name State 2
- `year`, Year of observation
- `fcwinit`, MID initiation t+1
- `fcwongo`, MID ongoing t+1
- `lndist`, natural log of distance
- `finctlc`, count of low conflict events t+1
- `fincthc`, count of high conflict events t+1
- `polity1_adj`, polity2 combined score for A (+10)
- `polity2_adj`, polity2 combined score for B (+10)
- `polity_int`, polity2 interaction of each state's combined democracy–autocracy score(rescaled from 0 to 20) from the Polity IV project
- `s_wt_glo`, alliance similarity using Signorino and Ritter’s (1999) global weighted S score (accounts for similar foreign policy preferences)

