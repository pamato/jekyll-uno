{
    "collab_server" : "",
    "contents" : "\n\n\n## Gould & Fernandez brokerage roles\nlibrary(sna)\ng<-rgraph(15)cl<-rep(1:3,5)\n#Compute a brokerage object\nb<-brokerage(g,cl)summary(b)\n\n\n## Burt Structural Holes\nlibrary(egonet)\n# make a toy dataset\negomat <-  matrix(c(0,1,1,1,0,0,1,0,0),3,3)\ncolnames(egomat) <- rownames(egomat) <- c(\"EGO\", \"1P\", \"1A\")\nindex.egonet(egomat)\n# an example with self defined index\nmy.outdegree <- function(dat) degree(dat,cmod=\"outdegree\")[1]\nindex.egonet(egomat,index=c(\"effsize\",\"constraint\",\"outdegree\",\"indegree\",\n                            \"efficiency\", \"centralization\", \"gden\", \"ego.gden\", \n                            my.outdegree=call(\"my.outdegree\",dat=egomat)))\n#Restricts the \\code{outdegree} and \\code{efficiency} to \"EGO\" and nodes with \"P\" in the name\nindex.egonet(egomat,index=c(\"outdegree\",\"efficiency\"),subset=\"P\")\n\n\n## E-I index (Homophily) ##\n\n\n## Heterogeneity (Blau's IQV index)\n\n\n\n\n\n\nsetwd(\"/Users/pauloserodio/Dropbox/Teaching/Summer Schools & Workshops/Oxford Spring School 2017/Introduction to Network Analysis/Day 3 - Social Capital, Brokerage & Equivalences/lecture notes/practice/data/\")\n\n\ndetach(package:igraph, unload=TRUE)\npackages <- list(\"plotrix\",\"ergm\",\"boot\",\"grid\",\"ggplot2\",\"MASS\",\"lattice\",\"plyr\",\n                 \"latticeExtra\",\"gridExtra\",\"pscl\",\"sna\", \"statnet\",\"foreign\", \"vcd\",\n                 \"coda\", \"network\", \"egonet\")\n\n#for (pack in packages){\n#  install.packages(pack)\n#}\n\n\n## Load Packages ##\nlapply(packages, require, character.only=T)\n\n\n## Binary Networks ##\n\nyear <- seq(2012, 2013, by=1)\nfor (y in year){\n  edgelist.name <- paste(\"matrix\", y, sep=\".\")\n  attr.name <- paste(\"attr\", y, sep=\".\")\n  net.name <- paste(\"net\", y, sep=\".\")\n  edgelist.data <- as.matrix(table(read.dta(paste(\"edgelist\", y, \".dta\", sep=\"\"))))\n  edgelist.data <- edgelist.data %*% t(edgelist.data)\n  diag(edgelist.data) <- 0\n  edgelist.data[edgelist.data > 1] <- 1\n  attr.data <- read.dta(paste(\"attr\", y, \".dta\", sep=\"\"), convert.factors=F)\n  network <- network(edgelist.data, directed=FALSE,ignore.eval=FALSE,names.eval='grants')\n  #edgelist.data <- edgelist.data[-isolates(network), -isolates(network)] # remove isolates\n  #attr.data <- attr.data[-]\n  assign(edgelist.name, value = edgelist.data)\n  assign(attr.name, value=attr.data)\n  assign(net.name, value=network)\n  rm(edgelist.data, attr.data, attr.name, edgelist.name, network, net.name)\n}\n\n\n######################################################\n############### 1. Centrality measures ###############\n######################################################\n\n## Functions\n\ncloseness2 <- function(x){ # Create an alternate closeness function!\n  geo <- 1/geodist(x)$gdist # Get the matrix of 1/geodesic distance\n  diag(geo) <- 0 # Define self-ties as 0\n  apply(geo, 1, sum) # Return sum(1/geodist) for each vertex\n}\nattr.2012$minfem <- 0\nattr.2012$minfem[attr.2012$gender == \"Female\" & attr.2012$minority == 1] <- 1\nattr.2012$minority <- factor(attr.2012$minority, \n                                 labels= c(\"No\", \"Yes\"))\nattr.2012$minfem <- factor(attr.2012$minfem, \n                                 labels= c(\"No\", \"Yes\"))\n\n## Degree centrality\n\ndeg <- degree(matrix.2012, gmode=\"graph\")\nbet <- betweenness(matrix.2012, gmode=\"graph\", diag=FALSE, rescale=TRUE)\neig <- evcent(matrix.2012, gmode=\"graph\")\nclo <- closeness2(matrix.2012)\n\n# By gender, minority & cross-product of both\n\ndeg.f <- degree(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$gender == \"Female\"))\ndeg.m <- degree(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$gender == \"Male\"))\nbet.f <- betweenness(matrix.2012, gmode=\"graph\", diag=FALSE, rescale=TRUE,\n                          nodes=which(attr.2012$gender == \"Female\"))\nbet.m <- betweenness(matrix.2012, gmode=\"graph\", diag=FALSE, rescale=TRUE,\n                        nodes=which(attr.2012$gender == \"Male\"))\neig.f <- evcent(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$gender == \"Female\"))\neig.m <- evcent(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$gender == \"Male\"))\nclo.f <- clo[-which(attr.2012$gender == \"Male\")] ## return closeness scores, except males.\nclo.m <- clo[-which(attr.2012$gender == \"Female\")]\n#minority\ndeg.min <- degree(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minority == \"Yes\"))\ndeg.maj <- degree(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minority == \"No\"))\nbet.min <- betweenness(matrix.2012, gmode=\"graph\", diag=FALSE, rescale=TRUE,\n                          nodes=which(attr.2012$minority == \"Yes\"))\nbet.maj <- betweenness(matrix.2012, gmode=\"graph\", diag=FALSE, rescale=TRUE,\n                        nodes=which(attr.2012$minority == \"No\"))\neig.min <- evcent(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minority == \"Yes\"))\neig.maj <- evcent(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minority == \"No\"))\nclo.min <- clo[-which(attr.2012$minority == \"No\")] ## return closeness scores, except males.\nclo.maj <- clo[-which(attr.2012$minority == \"Yes\")]\n#interaction\ndeg.fmin <- degree(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minfem == \"Yes\"))\ndeg.gmaj <- degree(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minfem == \"No\"))\nbet.fmin <- betweenness(matrix.2012, gmode=\"graph\", diag=FALSE, rescale=TRUE,\n                          nodes=which(attr.2012$minfem == \"Yes\"))\nbet.gmaj <- betweenness(matrix.2012, gmode=\"graph\", diag=FALSE, rescale=TRUE,\n                        nodes=which(attr.2012$minfem == \"No\"))\neig.fmin <- evcent(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minfem == \"Yes\"))\neig.gmaj <- evcent(matrix.2012, gmode=\"graph\", nodes=which(attr.2012$minfem == \"No\"))\nclo.fmin <- clo[-which(attr.2012$minfem == \"No\")] ## return closeness scores, except males.\nclo.gmaj <- clo[-which(attr.2012$minfem == \"Yes\")]\n\n\n# Dataset for Plotting\n\ncentrality <- data.frame(gender = attr.2012$gender, minority = attr.2012$minority,\n                         minfem = attr.2012$minfem, degree.gender = NA, betweenness.gender = NA, eigenvector.gender = NA,\n                         closeness.gender = NA, degree.minority = NA, betweenness.minority = NA, eigenvector.minority = NA,\n                         closeness.minority = NA, degree.minfem = NA, betweenness.minfem = NA, eigenvector.minfem = NA,\n                         closeness.minfem = NA)\n# By gender\ncentrality$degree.gender[which(attr.2012$gender == \"Male\")] <- deg.m\ncentrality$degree.gender[which(attr.2012$gender == \"Female\")] <- deg.f\ncentrality$betweenness.gender[which(attr.2012$gender == \"Male\")] <- bet.m\ncentrality$betweenness.gender[which(attr.2012$gender == \"Female\")] <- bet.f\ncentrality$eigenvector.gender[which(attr.2012$gender == \"Male\")] <- eig.m\ncentrality$eigenvector.gender[which(attr.2012$gender == \"Female\")] <- eig.f\ncentrality$closeness.gender[which(attr.2012$gender == \"Male\")] <- clo.m\ncentrality$closeness.gender[which(attr.2012$gender == \"Female\")] <- clo.f\n# By minority\ncentrality$degree.minority[which(attr.2012$minority == \"Yes\")] <- deg.min\ncentrality$degree.minority[which(attr.2012$minority == \"No\")] <- deg.maj\ncentrality$betweenness.minority[which(attr.2012$minority == \"Yes\")] <- bet.min\ncentrality$betweenness.minority[which(attr.2012$minority == \"No\")] <- bet.maj\ncentrality$eigenvector.minority[which(attr.2012$minority == \"Yes\")] <- eig.min\ncentrality$eigenvector.minority[which(attr.2012$minority == \"No\")] <- eig.maj\ncentrality$closeness.minority[which(attr.2012$minority == \"Yes\")] <- clo.min\ncentrality$closeness.minority[which(attr.2012$minority == \"No\")] <- clo.maj\n# By gender & minority\ncentrality$degree.minfem[which(attr.2012$minfem == \"Yes\")] <- deg.fmin\ncentrality$degree.minfem[which(attr.2012$minfem == \"No\")] <- deg.gmaj\ncentrality$betweenness.minfem[which(attr.2012$minfem == \"Yes\")] <- bet.fmin\ncentrality$betweenness.minfem[which(attr.2012$minfem == \"No\")] <- bet.gmaj\ncentrality$eigenvector.minfem[which(attr.2012$minfem == \"Yes\")] <- eig.fmin\ncentrality$eigenvector.minfem[which(attr.2012$minfem == \"No\")] <- eig.gmaj\ncentrality$closeness.minfem[which(attr.2012$minfem == \"Yes\")] <- clo.fmin\ncentrality$closeness.minfem[which(attr.2012$minfem == \"No\")] <- clo.gmaj\n\n## Delete isolates\n\ncentrality <- centrality[-c(isolates(net.2012)),]\n\n\n\n## Plotting: Boxplots ##\nmeasures <- list(\"degree\", \"betweenness\", \"eigenvector\", \"closeness\")\nfor (m in measures){\n    cm <- paste(m, \"gender\", sep=\".\")\n    gender.p.2012 <- ggplot(data = centrality, aes(x = gender, y = centrality[[cm]])) +\n                  geom_boxplot(aes(fill = gender)) + theme_bw() +\n                  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n                        axis.title.y = element_text(size=14),\n                        axis.title.x  = element_text(size=12)) +\n                  xlab(\"\") + ylab(m) + ggtitle(\"2012\")+\n                  scale_fill_manual(name = \"Gender\", values = c(\"#FEE0D2\", \"#DE2D26\"))\n    cm <- paste(m, \"minority\", sep=\".\")\n    minority.p <- ggplot(data = centrality, aes(x = minority, y = centrality[[cm]])) +\n                  geom_boxplot(aes(fill = minority)) + theme_bw() +\n                  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n                        axis.title.y = element_text(size=14),\n                        axis.title.x  = element_text(size=12)) +\n                  xlab(\"Underrepresented Minority\") + ylab(m) + ggtitle(\"\")+\n                  scale_fill_manual(name = \"Minority\", values = c(\"#FEE0D2\", \"#DE2D26\"))\n    cm <- paste(m, \"minfem\", sep=\".\")\n    minfem.p <- ggplot(data = centrality, aes(x = minfem, y = centrality[[cm]])) +\n                  geom_boxplot(aes(fill = minfem)) + theme_bw() +\n                  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n                        axis.title.y = element_text(size=14),\n                        axis.title.x  = element_text(size=12)) +\n                  xlab(\"Minority & Female\") + ylab(m) + ggtitle(\"\")+\n                  scale_fill_manual(name = \"Female Minority\", values = c(\"#FEE0D2\", \"#DE2D26\"))\n    plot.name <- paste(m, \"_box\",\".pdf\", sep=\".\")\n    pdf(plot.name, width = 10, height = 6)\n    grid.arrange(gender.p, minority.p, minfem.p, ncol=3)\n    dev.off()\n}\n\n## Plotting: Histograms ##\nmeasures <- list(\"degree\", \"betweenness\", \"eigenvector\", \"closeness\")\nfor (m in measures){\n  cm <- paste(m, \"gender\", sep=\".\")\n  means <- data.frame(measure = centrality[[cm]],cond = centrality$gender)\n  means <- ddply(means, .(cond), summarize, cent.mean=mean(measure))\n  gender.p <- ggplot(data = centrality, aes(x = centrality[[cm]], fill=gender)) +\n              geom_histogram(alpha=.5, position=\"identity\") +\n              #geom_density(alpha=.3) +\n              geom_vline(data=means, aes(xintercept=cent.mean,  colour=cond),\n              linetype=\"dashed\", size=1) +\n              theme(axis.text.x = element_text(angle = 45, hjust = 1),\n              axis.title.y = element_text(size=14), axis.title.x  = element_text(size=12)) +\n              xlab(\"\") + ylab(m) + ggtitle(\"\") +\n              scale_fill_manual(name = \"Gender\", values = c(\"#FF8585\", \"#66E0FF\"))\n  cm <- paste(m, \"minority\", sep=\".\")\n  means <- data.frame(measure = centrality[[cm]],cond = centrality$minority)\n  means <- ddply(means, .(cond), summarize, cent.mean=mean(measure))\n  minority.p <- ggplot(data = centrality, aes(x = centrality[[cm]], fill=minority)) +\n              geom_histogram(alpha=.5, position=\"identity\") +\n              #geom_density(alpha=.3) +\n              geom_vline(data=means, aes(xintercept=cent.mean,  colour=cond),\n              linetype=\"dashed\", size=1) +\n              theme(axis.text.x = element_text(angle = 45, hjust = 1),\n              axis.title.y = element_text(size=14), axis.title.x  = element_text(size=12)) +\n              xlab(\"\") + ylab(m) + ggtitle(\"\") +\n              scale_fill_manual(name = \"Minority\", values = c(\"#FF8585\", \"#66E0FF\"))\n  cm <- paste(m, \"minfem\", sep=\".\")\n  means <- data.frame(measure = centrality[[cm]],cond = centrality$minfem)\n  means <- ddply(means, .(cond), summarize, cent.mean=mean(measure))\n  minfem.p <- ggplot(data = centrality, aes(x = centrality[[cm]], fill=minfem)) +\n              geom_histogram(alpha=.5, position=\"identity\") +\n              #geom_density(alpha=.3) +\n              geom_vline(data=means, aes(xintercept=cent.mean,  colour=cond),\n              linetype=\"dashed\", size=1) +\n              theme(axis.text.x = element_text(angle = 45, hjust = 1),\n              axis.title.y = element_text(size=14), axis.title.x  = element_text(size=12)) +\n              xlab(\"\") + ylab(m) + ggtitle(\"\") +\n              scale_fill_manual(name = \"Female Minority\", values = c(\"#FF8585\", \"#66E0FF\"))\n  plot.name <- paste(m, \"_hist\", \".pdf\", sep=\"\")\n  pdf(plot.name, width = 10, height = 10)\n  grid.arrange(gender.p, minority.p, minfem.p, nrow=3)\n  dev.off()\n}\n\n\n#####################################################################\n############### 3. Structural Holes & Brokerage Roles ###############\n#####################################################################\n\n\n### Structural Holes\n\nmat12 <- matrix.2012[-isolates(net.2012), -isolates(net.2012)]\nattributes.12 <- attr.2012[-c(isolates(net.2012)),]\nmat13 <- matrix.2013[-isolates(net.2013), -isolates(net.2013)]\nattributes.13 <- attr.2013[-c(isolates(net.2013)),]\n\n\n# Extract ego-networks and calculate measures\nego.nets.12 <- ego.extract(mat12, neighborhood=\"combined\")\nresults.12 <- data.frame(piid = attributes.12$piid, gender = attributes.12$gender, ego=NA,\n                      effsize = NA, constraint = NA, efficiency = NA, hierarchy = NA, size = NA)\nfor (i in 1:length(ego.nets.12)){\n  ego <- names(ego.nets.12[i])\n  ego.net <- ego.nets.12[i][[1]]\n  dimnames(ego.net) <- NULL\n  colnames(ego.net) <- rownames(ego.net) <- c(\"EGO\", 2:ncol(ego.net))\n  sh <- index.egonet(ego.net)\n  results.12$size[i] <- nrow(ego.net)-1\n  results.12$ego[i] <- ego\n  results.12$effsize[i] <- sh[1]\n  results.12$constraint[i] <- sh[2]\n  results.12$efficiency[i] <- sh[5]\n  results.12$hierarchy[i] <- sh[6]\n}\n\neffsize.g <- ddply(results.12, .(gender), summarize, mean=mean(effsize))\nconstraint.g <- ddply(results.12, .(gender), summarize, mean=mean(constraint))\nefficiency.g <- ddply(results.12, .(gender), summarize, mean=mean(efficiency))\nhierarchy.g <- ddply(results.12, .(gender), summarize, mean=mean(hierarchy))\nsize.g <- ddply(results.12, .(gender), summarize, mean=mean(size))\n\n\ntable(results.12$size[results.12$gender == \"Female\"])\ntable(results.12$size[results.12$gender == \"Male\"])\nplot(density(results.12$size[results.12$gender == \"Male\"]))\nplot(density(results.12$size[results.12$gender == \"Female\"]))\n\n\n### Brokerage Roles ###\nmat12 <- matrix.2012[-isolates(net.2012), -isolates(net.2012)]\nattributes.12 <- attr.2012[-c(isolates(net.2012)),]\n\n\n# Gender Brokerage; observed scores\nbrokerage.12 <- brokerage(mat12, attributes.12$gender)\nsummary(brokerage.12)\npositions <- data.frame(brokerage.12$z.nli) # Raw Observed Brokerage Scores by vertex\ncolnames(positions) <- c(\"piid\", \"coordinator\", \"consultant\", \"representative\",\n                         \"gatekeeper\", \"liaison\")\npositions$gender <- attributes.12$gender\n\ncoord <- ddply(positions, .(gender), summarize, sum=mean(coordinator))\nconsul <- ddply(positions, .(gender), summarize, sum=mean(consultant))\nrep <- ddply(positions, .(gender), summarize, sum=mean(representative))\ngate <- ddply(positions, .(gender), summarize, sum=mean(gatekeeper))\nliaison <- ddply(positions, .(gender), summarize, sum=mean(liaison))\n##############################\n\n# Department Brokerage; raw scores\nbrok.dep.12 <- brokerage(mat12, attributes.12$department)\npositions.dep <- data.frame(brok.dep.12$raw.nli) # Raw Observed Brokerage Scores by vertex\ncolnames(positions.dep) <- c(\"piid\", \"coordinator\", \"consultant\", \"representative\",\n                         \"gatekeeper\", \"liaison\")\npositions.dep$gender <- attributes.12$gender\n\ncoord <- ddply(positions.dep, .(gender), summarize, sum=sum(coordinator))\nconsul <- ddply(positions.dep, .(gender), summarize, sum=sum(consultant))\nrep <- ddply(positions.dep, .(gender), summarize, sum=sum(representative))\ngate <- ddply(positions.dep, .(gender), summarize, sum=sum(gatekeeper))\nliaison <- ddply(positions.dep, .(gender), summarize, sum=sum(liaison))\n\nbrok.dep.12$exp.nli # Raw Expected Brokerage Scores by vertex\nbrok.dep.12$raw.grp # Raw Observed Brokerage Scores by group\nbrok.dep.12$exp.grp # Raw Expected Brokerage Scores by group\n\n\n### Random Graph - brokerage roles ###\n\ng<-rgraph(15)\ncl<-rep(1:3,5)\nb<-brokerage(g,cl)\nsummary(b)\n\n\n######################################################\n############# 4. Ego-net Composition    ##############\n######################################################\n\n\n### Functions\nget_iqvs <- function(graph, attribute) {\n \n    mat <- graph\n    attr_levels = attribute\n    num_levels = length(unique(attr_levels))\n    iqvs = rep(0, nrow(mat))\n    blau_index = rep(0, nrow(mat))\n \n    for (ego in 1:nrow(mat)) {\n         \n        # initialize actor-specific variables\n        alter_attr_counts = rep(0, num_levels)\n        num_alters_this_ego = 0\n        sq_fraction_sum = 0\n     \n        for (alter in 1:ncol(mat)) {\n             \n            # only examine alters that are actually tied to ego\n            if (mat[ego, alter] == 1) {\n                 \n                num_alters_this_ego = num_alters_this_ego + 1\n \n                # get the alter's level on the attribute \n                alter_attr = attribute[alter]\n \n                # increment the count of alters with this level\n                # of the attribute by 1\n                alter_attr_counts[alter_attr] <- alter_attr_counts[alter_attr] + 1\n            }\n        }\n \n         for (i in 1:num_levels) {\n            attr_fraction = alter_attr_counts[i] /\n                num_alters_this_ego\n            sq_fraction_sum = sq_fraction_sum + attr_fraction ^ 2\n        }\n         \n        # now we can compute the ego's blau index...\n        blau_index[ego] = 1 - sq_fraction_sum\n        # and the ego's IQV, which is just a normalized blau index\n        iqvs[ego] = blau_index[ego] / (1 - (1 / num_levels))\n    }\n \n    return(list(iqvs, blau_index))\n}\n\n\n### Data\n\nmat12 <- matrix.2012[-isolates(net.2012), -isolates(net.2012)]\nmat13 <- matrix.2013[-isolates(net.2013), -isolates(net.2013)]\nattributes.12 <- attr.2012[-c(isolates(net.2012)),]\nattributes.13 <- attr.2013[-c(isolates(net.2013)),]\n\n## Export \nwrite.table(mat12, \"mat12.csv\", sep=\",\", row.names=TRUE, col.names=TRUE)\nwrite.table(mat13, \"mat13.csv\", sep=\",\", row.names=TRUE, col.names=TRUE)\nwrite.table(attributes.12, \"attr12.csv\", sep=\",\", row.names=FALSE, col.names=TRUE)\nwrite.table(attributes.13, \"attr13.csv\", sep=\",\", row.names=FALSE, col.names=TRUE)\n\n## Attributes\n\nethn.12 <- attributes.12$ethnicity\nethn.12[attributes.12$ethnicity != \"White\"] <- 1\nethn.12[attributes.12$ethnicity == \"White\"] <- 0\ndep.12 <- as.numeric(as.factor(attributes.12$department))\ngender.12 <- as.numeric(as.factor(attributes.12$gender))\n\n\n## How function works\niqv.gender <- get_iqvs(graph, attribute)[[1]]\nblau.gender <- get_iqvs(graph, attribute)[[2]]\n\n\n#################################################################################\n### Heterogeneity: Index of Qualitative Variation (perfect heterogeneity = 1) ###\n#################################################################################\n\n## Inter-disciplinary heterogeneity by gender\n\niqv.dep <- get_iqvs(mat12, dep.12)[[1]] ## Heterogeneity by discipline\niqv.male <- iqv.dep[gender.12 == 2]\niqv.female <- iqv.dep[gender.12 == 1]\niqv.male.mean <- mean(iqv.dep[gender.12 == 2]) # 0.395\niqv.female.mean <- mean(iqv.dep[gender.12 == 1]) # 0.397\niqv.male.sd <- sd(iqv.dep[gender.12 == 2]) # 0.344\niqv.female.sd <- sd(iqv.dep[gender.12 == 1]) # 0.353\nheterogeneity <- data.frame(gender = attributes.12$gender,iqv = 0)\nheterogeneity$iqv[which(attributes.12$gender == \"Male\")] <- iqv.male\nheterogeneity$iqv[which(attributes.12$gender == \"Female\")] <- iqv.female\nmeans <- data.frame(measure = heterogeneity$iqv, cond = heterogeneity$gender)\nmeans <- ddply(means, .(cond), summarize, cent.mean=mean(measure))\n\nhet.dept.12 <- ggplot(data = heterogeneity, aes(x = iqv, fill=gender)) +\n                #geom_histogram(alpha=.5, position=\"identity\") +\n                geom_density(alpha=.7) + \n                geom_vline(data=means, aes(xintercept=cent.mean),  colour=c(\"#FF8585\", \"#19A3FF\"),\n                linetype=\"dashed\", size=1, alpha=.7) + ylim(0,3.2) + xlim(0,1) + \n                theme(axis.text.x = element_text(angle = 45, hjust = 1),\n                axis.title.y = element_text(size=14), axis.title.x  = element_text(size=12)) +\n                xlab(\"Heterogeneity Index\") + ylab(\"\") + ggtitle(\"2012\") + ylab(\"Density\") +\n                scale_fill_manual(name = \"Gender\", values = c(\"#FF8585\", \"#19A3FF\"))\npdf(\"het_variance_12_dept.pdf\", width=10, height=7)\nhet.dept.12\ndev.off()\n\n## Gender heterogeneity, by gender\n\ngender.12 <- as.numeric(as.factor(attributes.12$gender))\niqv.gen <- get_iqvs(mat12, gender.12)[[1]] ## Heterogeneity by discipline\nmat12[2,]\niqv.male <- iqv.gen[gender.12 == 2]\niqv.female <- iqv.gen[gender.12 == 1]\niqv.male.mean <- mean(iqv.gen[gender.12 == 2]) # 0.395\niqv.female.mean <- mean(iqv.gen[gender.12 == 1]) # 0.397\niqv.male.sd <- sd(iqv.gen[gender.12 == 2]) # 0.344\niqv.female.sd <- sd(iqv.gen[gender.12 == 1]) # 0.353\nheterogeneity <- data.frame(gender = attributes.12$gender,iqv = 0)\nheterogeneity$iqv[which(attributes.12$gender == \"Male\")] <- iqv.male\nheterogeneity$iqv[which(attributes.12$gender == \"Female\")] <- iqv.female\nmeans <- data.frame(measure = heterogeneity$iqv, cond = heterogeneity$gender)\nmeans <- ddply(means, .(cond), summarize, cent.mean=mean(measure))\n\nhet.gender.12 <- ggplot(data = heterogeneity, aes(x = iqv, fill=gender)) +\n                #geom_histogram(alpha=.5, position=\"identity\") +\n                geom_density(alpha=.7) +\n                geom_vline(data=means, aes(xintercept=cent.mean),  colour=c(\"#FF8585\", \"#19A3FF\"),\n                linetype=\"dashed\", size=1) + ylim(0,1.5) + xlim(0,1) + \n                theme(axis.text.x = element_text(angle = 45, hjust = 1),\n                axis.title.y = element_text(size=14), axis.title.x  = element_text(size=12)) +\n                xlab(\"Heterogeneity Index\") + ylab(\"\") + ggtitle(\"2012\") + ylab(\"Density\") +\n                scale_fill_manual(name = \"Gender\", values = c(\"#FF8585\", \"#19A3FF\"))\npdf(\"het_variance_12_gender.pdf\", width=10, height=7)\nhet.gender.12\ndev.off()\n\n\n\n#### Combine graphs #####\n\n\npdf(\"het_variance_gender.pdf\", width=10, height=7)\ngrid.arrange(het.gender.07, het.gender.12, nrow=2)\ndev.off()\n\npdf(\"het_variance_dept.pdf\", width=10, height=7)\ngrid.arrange(het.dept.07, het.dept.12, nrow=2)\ndev.off()\n\n\n\n\n\n\n\n## Structural Equivalence ##\n\n# Formally speaking, a pair of actors is said to be structurally equivalent if \n# they are tied to the same set of alters. In practice, actors are almost never exactly \n# structural equivalent to one another. To get around this problem, we first measure the degree\n# of structural equivalence between each pair of actors and then use these measures to look for \n# groups of actors who are roughly comparable to one another. \n\n#Structural equivalence can be measured \n# in a number of different ways, with correlation and Euclidean distance emerging as popular options. \n# Similarly, there are a number of methods for identifying groups of structurally equivalent actors. \n# The equiv.clust routine included in the sna package in R, for example, relies on hierarchical cluster\n# analysis (HCA). While the designation of positions is less cut and dry, one can use multidimensional \n# scaling (MDS) in a similar manner. MDS and HCA can also be used in combination, with the former \n# serving as a form of pre-processing. Either way, once clusters of structurally equivalent actors \n# have been identified, we can construct a reduced graph depicting the relationship between the \n# resulting groups.\n\n\n# 1. Profile Similarity\n\ninstall.packages(\"NetCluster\")\nlibrary(NetCluster)\ndetach(package:sna, unload=TRUE)\nlibrary(igraph)\n\n\n\n###\n#2. LOADING AND FORMATTING DATA\n###\n \ndata(studentnets.M182, package = \"NetData\")\n \n# Reduce to non-zero edges and build a graph object\nm182_full_nonzero_edges <- subset(m182_full_data_frame, (friend_tie > 0 | social_tie > 0 | task_tie > 0))\nhead(m182_full_nonzero_edges)\n \nm182_full <- graph.data.frame(m182_full_nonzero_edges) \nsummary(m182_full)\n \n# Create sub-graphs based on edge attributes\nm182_friend <- delete.edges(m182_full, E(m182_full)[E(m182_full)$friend_tie==0])\nsummary(m182_friend)\n \nm182_social <- delete.edges(m182_full, E(m182_full)[E(m182_full)$social_tie==0])\nsummary(m182_social)\n \nm182_task <- delete.edges(m182_full, E(m182_full)[E(m182_full)$task_tie==0])\nsummary(m182_task)\n \n# Look at the plots for each sub-graph\npdf(\"6.1_m182_studentnet_friend_social_task_plots.pdf\", width = 10)\npar(mfrow = c(1,3))\n \nfriend_layout <- layout.fruchterman.reingold(m182_friend)\nplot(m182_friend, layout=friend_layout, main = \"friend\", edge.arrow.size=.5)\n \nsocial_layout <- layout.fruchterman.reingold(m182_social)\nplot(m182_social, layout=social_layout, main = \"social\", edge.arrow.size=.5)\n \ntask_layout <- layout.fruchterman.reingold(m182_task)\nplot(m182_task, layout=task_layout, main = \"task\", edge.arrow.size=.5)\ndev.off()\n \n###\n# 3. HIERARCHICAL CLUSTERING ON SOCIAL & TASK TIES\n###\n \n# We'll use the \"task\" and \"social\" sub-graphs together as the\n# basis for our structural equivalence methods. First, we'll use\n# the task graph to generate an adjacency matrix.\n#\n# This matrix represents task interactions directed FROM the \n# row individual TO the column individual. \nm182_task_matrix_row_to_col <- as.matrix(get.adjacency(m182_task, attr='task_tie'))\nm182_task_matrix_row_to_col\n \n# To operate on a binary graph, simply leave off the \"attr\" \n# parameter:\nm182_task_matrix_row_to_col_bin <- as.matrix(get.adjacency(m182_task))\nm182_task_matrix_row_to_col_bin\n \n# For this lab, we'll use the valued graph. The next step is to \n# concatenate it with its transpose in order to capture both \n# incoming and outgoing task interactions.\nm182_task_matrix_col_to_row <- t(m182_task_matrix_row_to_col)\nm182_task_matrix_col_to_row\n \nm182_task_matrix <- rbind(m182_task_matrix_row_to_col, m182_task_matrix_col_to_row)\nm182_task_matrix\n \n# Next, we'll use the same procedure to add social-interaction\n# information.\nm182_social_matrix_row_to_col <- as.matrix(get.adjacency(m182_social, attr='social_tie'))\nm182_social_matrix_row_to_col\n \nm182_social_matrix_row_to_col_bin <- as.matrix(get.adjacency(m182_social))\nm182_social_matrix_row_to_col_bin\n \nm182_social_matrix_col_to_row <- t(m182_social_matrix_row_to_col)\nm182_social_matrix_col_to_row\n \nm182_social_matrix <- rbind(m182_social_matrix_row_to_col, m182_social_matrix_col_to_row)\nm182_social_matrix\n \nm182_task_social_matrix <- rbind(m182_task_matrix, m182_social_matrix)\nm182_task_social_matrix\n \n# Now we have a single 4n x n matrix that represents both in- and\n# out-directed task and social communication. From this, we can\n# generate an n x n correlation matrix that shows the degree of\n# structural equivalence of each actor in the network. \nm182_task_social_cors <- cor(m182_task_social_matrix)\nm182_task_social_cors\n \n# To use correlation values in hierarchical NetCluster, they must \n# first be coerced into a \"dissimilarity structure\" using dist().\n# We subtract the values from 1 so that they are all greater than \n# or equal to 0; thus, highly dissimilar (i.e., negatively \n# correlated) actors have higher values.\ndissimilarity <- 1 - m182_task_social_cors\nm182_task_social_dist <- as.dist(dissimilarity)\n?as.dist\nm182_task_social_dist\n \n# Note that it is also possible to use dist() directly on the \n# matrix. However, since cor() looks at associations between \n# columns and dist() looks at associations between rows, it is\n# necessary to transpose the matrix first.\n#\n# A variety of distance metrics are available; Euclidean \n# is the default.\n#m182_task_social_dist <- dist(t(m182_task_social_matrix))\n#m182_task_social_dist\n\n###\n# Hierarchical Clustering\n###\n\n# hclust() performs a hierarchical agglomerative NetCluster \n# operation based on the values in the dissimilarity matrix \n# yielded by as.dist() above. The standard visualization is a \n# dendrogram. By default, hclust() agglomerates clusters via a\n# \"complete linkakage\" algorithm, determining cluster proximity\n# by looking at the distance of the two points across clusters\n# that are farthest away from one another. This can be changed via\n# the \"method\" parameter.\n \npdf(\"6.2_m182_studentnet_social_hclust.pdf\")\nm182_task_social_hclust <- hclust(m182_task_social_dist)\nplot(m182_task_social_hclust)\ndev.off()\n \n# cutree() allows us to use the output of hclust() to set\n# different numbers of clusters and assign vertices to clusters\n# as appropriate. For example:\n?cutree\ncutree(m182_task_social_hclust, k=2) # k is the desired number of groups\n \n# Now we'll try to figure out the number of clusters that best \n# describes the underlying data. To do this, we'll loop through\n# all of the possible numbers of clusters (1 through n, where n is\n# the number of actors in the network). For each solution\n# corresponding to a given number of clusters, we'll use cutree()\n# to assign the vertices to their respective clusters \n# corresponding to that solution.\n#\n# From this, we can generate a matrix of within- and between-\n# cluster correlations. Thus, when there is one cluster for each \n# vertex in the network, the cell values will be identical \n\n# We can then correlate each by-cluster matrix with the observed\n# correlation matrix to see how well the by-cluster matrix fits\n# the data. We'll store the correlation for each number of\n# clusters in a vector, which we can then plot.\n \n# First, we initialize a vector for storing the correlations and \n# set a variable for our number of vertices.\nclustered_observed_cors = vector()\nnum_vertices = length(V(m182_task))\n \n# Next, we loop through the different possible cluster \n# configurations, produce matrices of within- and between-\n# cluster correlations, and correlate these by-cluster matrices\n# with the observed correlation matrix.\n\n\npdf(\"6.3_m182_studentnet_task_social_clustered_observed_corrs.pdf\")\nclustered_observed_cors <- NetCluster::clustConfigurations(num_vertices,m182_task_social_hclust,m182_task_social_cors)\nclustered_observed_cors\nplot(clustered_observed_cors$correlations)\ndev.off()\n \n# From  this,  the  function  generates  a  matrix  of  within-  and  between-  cluster  correlations.   \n# Whenthere is one cluster for each vertex in the network, the cell values will be identical to the \n# observed correlation matrix. When there is one cluster for the whole network, the values will all be equal \n# to the average correlation across the observed matrix\n\nclustered_observed_cors$correlations\n# From a visual inspection of the correlation matrix, we can \n# decide on the proper number of clusters in this network. \n# For this network, we'll use 4. (Note that the 1-cluster \n# solution doesn't appear on the plot because its correlation \n# with the observed correlation matrix is undefined.)\nnum_clusters = 4\nclusters <- cutree(m182_task_social_hclust, k = num_clusters)\nclusters\n \ncluster_cor_mat <- NetCluster::clusterCorr(m182_task_social_cors,\n                                            clusters)\ncluster_cor_mat\n \n# Let's look at the correlation between this cluster configuration \n# and the observed correlation matrix. This should match the \n# corresponding value from clustered_observed_cors above.\nsna::gcor(cluster_cor_mat, m182_task_social_cors)\n\n\n\n\n\n\n# 2. Blockmodeling [note: # of blocks is counted on the diagonal]\n\n  # 2.1. CONCOR\n\n# The algorithm takes it name from the simple trick on which it is based, namely the CONvergence of iterated CORrelations. \n# We are all familiar with the idea of using correlation to measure the similarity between columns of a data matrix. As \n# it turns out, you can also use correlation to measure the degree of similarity between the columns of the resulting correlation \n# matrix. In other words, you can use correlation to measure the similarity of similarities. If you repeat this procedure over and \n# over, you eventually end up with a matrix whose entries take on one of two values: 1 or -1. The final matrix can then be permuted \n# to produce blocks of 1s and -1s, with each block representing a group of structurally equivalent actors. Dividing the original \n# data accordingly, each of these groups can be further partitioned to produce a more fine-grained solution.\n\n\ndetach(package:igraph, unload=TRUE)\nlibrary(sna)\ndevtools::install_github(\"aslez/concoR\")\nlibrary(concoR)\ndata(\"bank_wiring\")\n\n#LOAD DATA \n\ndata(bank_wiring) \nbank_wiring\n# A word on the data: \n# These are the observational data on 14 Western Electric (Hawthorne Plant) employees from the bank wiring room first presented in \n# Roethlisberger & Dickson (1939). The employees worked in a single room and include two inspectors (I1 and I3), \n# three solderers (S1, S2 and S3), and nine wiremen or assemblers (W1 to W9). The interaction categories include: \n# RDGAM, participation in horseplay;  RDCON, participation in arguments about open windows;  RDPOS, friendship;  \n# RDNEG, antagonistic (negative) behavior; RDHLP, helping others with work; and \n# RDJOB, the number of times workers traded job assignments.\n\n\n#CHECK INITIAL CORRELATIONS\nm0 <- cor(do.call(rbind, bank_wiring)) \nround(m0, 2)\n\n\n#IDENTIFY BLOCKS USING A 4-BLOCK MODEL (TABLE IV) \nblks <- concor_hca(bank_wiring, p = 2) # p = desired number of partitions (count partitions in diagonal)\nblks\n\n\n#CHECK FIT USING SNA (TABLE V)\n#code below fails unless glabels are specified\n?blockmodel\nblk_mod <- blockmodel(bank_wiring, blks$block,\n            glabels = names(bank_wiring),\n            plabels = rownames(bank_wiring[[1]])) \nblk_mod\nplot(blk_mod)\n\n# Insofar as CONCOR uses correlation as a both a measure of structural equivalence as well as a means of identifying groups\n# of structurally equivalent actors, it is easy to forget that blockmodeling with CONCOR entails the same basic steps as \n# blockmodeling with HCA. The logic behind the two procedures is identical. Indeed, Breiger, Boorman, and Arabie (1975) \n# explicitly describe CONCOR as a hierarchical clustering algorithm. Note, however, that when it comes to measuring structural equivalence,\n# CONCOR relies exclusively on the use of correlation, whereas HCA can be made to work with most common measures of (dis)similarity.\n\n\n\n  # 2.2 From  equivalence hierarchical clustering\n\nrequire(sna)\n# Load data\ndata(\"bank_wiring\")\n\n# Create an equivalence clustering object. equiv.clust uses a definition of approximate equivalence\n# (equiv.fun) to form a hierarchical clustering of network positions.\n\nbw.games.eq <- equiv.clust(bank_wiring$Games, mode = \"graph\", glabels = rownames(bank_wiring$Games), plabels = rownames(bank_wiring$Games))\nplot(bw.games.eq, label=rownames(bank_wiring$Games))\n\n# we can now create an idealized bloackmodel using block density at a set level of height from our dendrogram\n# Count blocks in the diagonal\nbw.games.block <- blockmodel(bank_wiring$Games, bw.games.eq, h=4, mode=\"graph\")\nplot(bw.games.block, cex=0.1)\nbw.games.block\n\n# Visualze newly formed blocks by coloring them\ngplot(bank_wiring$Games, vertex.col = bw.games.block$block.membership, gmode=\"graph\")\ngplot(bw.games.block$block.model, gmode=\"graph\", label=rownames(bw.games.block$block.model), edge.lwd =\nbw.games.block$block.model*10)\n\n# take a look at the density distribution of block membership, and we will note\n# that the majority of our nodes fell into block 1, making this a central group \nplot(density(bw.games.block$block.membership))\n\n\n  # 2.3. REGE (clashes with sna package)\n\ninstall.packages(\"blockmodeling\")\nrequire(blockmodeling)\n\ngames.rege <- REGE(bank_wiring$Games)$E\nheatmap(games.rege)\n\n## Lazega Lawyers dataset\n\nlazega.friendship <- as.matrix(read.table(\"/Users/pauloserodio/Dropbox/Learning/Courses/Essex Summer School/Summer School 2014/Advanced Social Network Analysis/Week 2 Lectures/Day 7/friLaz.txt\",\n                    header=FALSE))\nrow.names(lazega.friendship) <- 1:nrow(lazega.friendship)\ncolnames(lazega.friendship) <- 1:ncol(lazega.friendship)\ndim(lazega.friendship)\n\n# Create REGE object\nlazega.rege <- REGE(lazega.friendship)$E\nheatmap(lazega.rege)\n\n# next, we can generate an actual matrix plot using a hierarchical clustering cutoff term\nplot.mat(lazega.rege, clu=cutree(hclust(as.dist(lazega.rege), method = \"ward.D\"), k=2))\n\n# While the matrix plot is much more difficult to read than our heatmap, it nonetheless provides an idea of \n# the dichotomy of our network. From here, we have the capacity to build out our core-periphery model.\n# More on this on Thursday!\n\n\n\n\n\n\n\n\n",
    "created" : 1558185569435.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "351|40|395|0|\n",
    "hash" : "3342057448",
    "id" : "985459BE",
    "lastKnownWriteTime" : 1490772469,
    "last_content_update" : 1558416448931,
    "path" : "~/Dropbox/Academic/Teaching/Summer Schools & Workshops/Oxford Spring School 2017/Introduction to Network Analysis/Day 3 - Social Capital, Brokerage & Equivalences/lecture notes/practice/day3 lab/day3_demonstration.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}